{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07FsQUqVDlcc"
   },
   "source": [
    "# Jay Bhanushali - 60009200047\n",
    "---\n",
    "# ML-II Lab 9: GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "th-swAok7A4a"
   },
   "outputs": [],
   "source": [
    "from numpy import zeros, ones, expand_dims, asarray \n",
    "from numpy.random import randn, randint \n",
    "from keras.datasets import fashion_mnist \n",
    "from keras.optimizers import Adam \n",
    "from keras.models import Model, load_model \n",
    "from keras.layers import Input, Dense, Reshape, Flatten \n",
    "from keras.layers import Conv2D, Conv2DTranspose, Concatenate \n",
    "from keras.layers import LeakyReLU, Dropout, Embedding \n",
    "from keras.layers import BatchNormalization, Activation \n",
    "from keras import initializers \n",
    "from keras.initializers import RandomNormal \n",
    "from keras.optimizers import Adam, RMSprop, SGD \n",
    "from matplotlib import pyplot \n",
    "import numpy as np \n",
    "\n",
    "from math import sqrt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "js0aN6hX-iGN",
    "outputId": "4567ebd9-46bf-4e51-ee75-d47320b844b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(X_train, _), (_, _) = fashion_mnist.load_data() \n",
    "X_train = X_train.astype(np.float32) / 127.5 - 1 \n",
    "X_train = np.expand_dims(X_train, axis=3) \n",
    "print(X_train.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kgZBSAGM7Mwi",
    "outputId": "26a19697-6133-4448-8606-9908d68b611e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def define_discriminator(in_shape=(28, 28, 1)): \n",
    "\n",
    "    init = RandomNormal(stddev=0.02)   \n",
    "\n",
    "    in_image = Input(shape=in_shape) \n",
    "\n",
    "    fe = Flatten()(in_image) \n",
    "\n",
    "    fe = Dense(1024)(fe) \n",
    "\n",
    "    fe = LeakyReLU(alpha=0.2)(fe) \n",
    "\n",
    "    fe = Dropout(0.3)(fe) \n",
    "\n",
    "    fe = Dense(512)(fe) \n",
    "\n",
    "    fe = LeakyReLU(alpha=0.2)(fe) \n",
    "\n",
    "    fe = Dropout(0.3)(fe) \n",
    "\n",
    "    fe = Dense(256)(fe) \n",
    "\n",
    "    fe = LeakyReLU(alpha=0.2)(fe) \n",
    "\n",
    "    fe = Dropout(0.3)(fe) \n",
    "\n",
    "    out = Dense(1, activation='sigmoid')(fe) \n",
    "\n",
    "    model = Model(in_image, out) \n",
    "\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)  \n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy']) \n",
    "\n",
    "    return model \n",
    "\n",
    "discriminator = define_discriminator() \n",
    "\n",
    "def define_generator(latent_dim):  \n",
    "\n",
    "    init = RandomNormal(stddev=0.02) \n",
    "\n",
    "    in_lat = Input(shape=(latent_dim,))  \n",
    "\n",
    "    gen = Dense(256, kernel_initializer=init)(in_lat) \n",
    "\n",
    "    gen = LeakyReLU(alpha=0.2)(gen) \n",
    "\n",
    "    gen = Dense(512, kernel_initializer=init)(gen) \n",
    "\n",
    "    gen = LeakyReLU(alpha=0.2)(gen) \n",
    "\n",
    "    gen = Dense(1024, kernel_initializer=init)(gen) \n",
    "\n",
    "    gen = LeakyReLU(alpha=0.2)(gen) \n",
    "\n",
    "    gen = Dense(28 * 28 * 1, kernel_initializer=init)(gen) \n",
    "\n",
    "    out_layer = Activation('tanh')(gen) \n",
    "\n",
    "    out_layer = Reshape((28, 28, 1))(gen) \n",
    "\n",
    "    model = Model(in_lat, out_layer) \n",
    "\n",
    "    return model \n",
    "\n",
    "generator = define_generator(100) \n",
    "\n",
    "def define_gan(g_model, d_model): \n",
    "\n",
    "    d_model.trainable = False \n",
    "\n",
    "    gan_output = d_model(g_model.output) \n",
    "\n",
    "    model = Model(g_model.input, gan_output) \n",
    "\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5) \n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy']) \n",
    "\n",
    "    return model \n",
    "\n",
    "gan_model = define_gan(generator, discriminator) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AF9WhsG4-tkW"
   },
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples): \n",
    "\n",
    "    x_input = randn(latent_dim * n_samples)   \n",
    "\n",
    "    z_input = x_input.reshape(n_samples, latent_dim) \n",
    "\n",
    "    return z_input \n",
    "\n",
    "def generate_real_samples(X_train, n_samples): \n",
    "\n",
    "    ix = randint(0, X_train.shape[0], n_samples)  # returns an integer number selected element from the specified range. \n",
    "\n",
    "    X = X_train[ix]   \n",
    "\n",
    "    y = ones((n_samples, 1))  \n",
    "\n",
    "    return X, y \n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples): \n",
    "\n",
    "    z_input = generate_latent_points(latent_dim, n_samples) \n",
    "\n",
    "    images = generator.predict(z_input)   \n",
    "\n",
    "    y = zeros((n_samples, 1)) \n",
    "\n",
    "    return images, y \n",
    "\n",
    "def summarize_performance(step, g_model, latent_dim, n_samples=100): \n",
    "\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples) \n",
    "\n",
    "    X = (X + 1) / 2.0 \n",
    "\n",
    "    for i in range(100): \n",
    "\n",
    "        pyplot.subplot(10, 10, 1 + i) \n",
    "\n",
    "        pyplot.axis('off') \n",
    "\n",
    "        pyplot.imshow(X[i, :, :, 0], cmap='gray_r') \n",
    "\n",
    "    filename2 = 'model_%04d.h5' % (step+1) \n",
    "\n",
    "    g_model.save(filename2) \n",
    "\n",
    "    print('>Saved: %s' % (filename2)) \n",
    "\n",
    "def save_plot(examples, n_examples): \n",
    "\n",
    "    for i in range(n_examples): \n",
    "\n",
    "        pyplot.subplot(sqrt(n_examples), sqrt(n_examples), 1 + i) \n",
    "\n",
    "        pyplot.axis('off') \n",
    "\n",
    "        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r') \n",
    "\n",
    "    pyplot.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DobA7ima7Wy6"
   },
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, X_train, latent_dim, n_epochs=100, n_batch=1000): \n",
    "\n",
    "    bat_per_epo = int(X_train.shape[0] / n_batch) \n",
    "\n",
    "    n_steps = bat_per_epo * n_epochs \n",
    "\n",
    "    for i in range(n_steps): \n",
    "\n",
    "        X_real, y_real = generate_real_samples(X_train, n_batch) \n",
    "\n",
    "        d_loss_r, d_acc_r = d_model.train_on_batch(X_real, y_real) \n",
    "\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_batch) \n",
    "\n",
    "        d_loss_f, d_acc_f = d_model.train_on_batch(X_fake, y_fake) \n",
    "\n",
    "        z_input = generate_latent_points(latent_dim, n_batch)  \n",
    "\n",
    "        y_gan = ones((n_batch, 1))  \n",
    "\n",
    "        g_loss, g_acc = gan_model.train_on_batch(z_input, y_gan) \n",
    "\n",
    "        print('>%d, dr[%.3f,%.3f], df[%.3f,%.3f], g[%.3f,%.3f]' % (i+1, d_loss_r,d_acc_r, d_loss_f,d_acc_f, g_loss,g_acc)) \n",
    "\n",
    "        if (i+1) % (bat_per_epo * 1) == 0: \n",
    "\n",
    "            summarize_performance(i, g_model, latent_dim) \n",
    "\n",
    "latent_dim = 100 \n",
    "\n",
    "train(generator, discriminator, gan_model, X_train, latent_dim, n_epochs=20, n_batch=64) \n",
    "\n",
    "model = load_model('model_18740.h5') \n",
    "\n",
    "latent_dim = 100 \n",
    "\n",
    "n_examples = 100 \n",
    "\n",
    "latent_points = generate_latent_points(latent_dim, n_examples) \n",
    "\n",
    "X  = model.predict(latent_points) \n",
    "\n",
    "X = (X + 1) / 2.0 \n",
    "\n",
    "save_plot(X, n_examples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdL_pB99Gfm0",
    "outputId": "c886d44c-65f5-49d8-cd73-bec1b3b7ba34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | Unrecognized alias: 'to', it will have no effect.\n",
      "[NbConvertApp] Converting notebook /content/ML2_EXP_9 (1).ipynb to html\n",
      "[NbConvertApp] ERROR | Notebook JSON is invalid: Additional properties are not allowed ('metadata' was unexpected)\n",
      "\n",
      "Failed validating 'additionalProperties' in stream:\n",
      "\n",
      "On instance['cells'][5]['outputs'][0]:\n",
      "{'metadata': {'tags': None},\n",
      " 'name': 'stdout',\n",
      " 'output_type': 'stream',\n",
      " 'text': '2/2 [==============================] - 0s 4ms/step\\n'\n",
      "         '>1, dr[0.723,...'}\n",
      "[NbConvertApp] Writing 2477922 bytes to /content/ML2_EXP_9 (1).html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert -to html '/content/ML2_EXP_9 (1).ipynb'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
