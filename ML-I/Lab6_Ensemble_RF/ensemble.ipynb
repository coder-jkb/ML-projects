{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             150 non-null    int64  \n",
      " 1   SepalLengthCm  150 non-null    float64\n",
      " 2   SepalWidthCm   150 non-null    float64\n",
      " 3   PetalLengthCm  150 non-null    float64\n",
      " 4   PetalWidthCm   150 non-null    float64\n",
      " 5   Species        150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.drop('Id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *DT FROM SCRATCH*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None,\n",
    "                left=None, right=None,info_gain=None,value=None):\n",
    "        # decision node atributes\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "\n",
    "        # leaf node attribute\n",
    "        self.value = value\n",
    "\n",
    "class DecisionTreeClassifier_scratch:\n",
    "    def __init__(self,min_samples_split=2,max_depth=2,mode='gini'):\n",
    "\n",
    "        # initializing the root of the tree\n",
    "        # tge root will be used to traverse through the tree\n",
    "        self.root = None\n",
    "        self.mode = mode\n",
    "\n",
    "        # stopping conditions\n",
    "        # if number of samples is less than min_samples_split \n",
    "        #       then consider it as leaf node (no more splitting)\n",
    "\n",
    "        self.min_samples_split=min_samples_split\n",
    "\n",
    "        # if depth reaches the max_depth then dont split the tree further\n",
    "        self.max_depth=max_depth\n",
    "\n",
    "    def build_tree(self,data,curr_depth=0):\n",
    "        # Build the tree recursively\n",
    "        #   all rows and columns from starting index to secondlast index\n",
    "        X = data[:,:-1] # trainig features\n",
    "        y = data[:,-1] # (target) feature to be classified \n",
    "        no_samples, no_features = np.shape(X) # number of samples , number of features\n",
    "\n",
    "        # split untill stopping conditions are met\n",
    "        if no_samples >=self.min_samples_split and curr_depth <= self.max_depth:\n",
    "            # find the best split\n",
    "            # best split is a dictionary returned by the best_split function\n",
    "            best_split = self.get_best_split(data, no_samples, no_features)\n",
    "            #   all rows and last column\n",
    "\n",
    "            # zero information gain means that node is already pure (leaf), \n",
    "            # hence info gain must be positive for spliting\n",
    "\n",
    "            if best_split['info_gain'] > 0:\n",
    "\n",
    "                # reursion\n",
    "                lst = self.build_tree(best_split[\"left_data\"], curr_depth+1)  # left sub tree\n",
    "                rst = self.build_tree(best_split[\"right_data\"], curr_depth+1) # right sub tree\n",
    "\n",
    "                return Node(best_split[\"feature_index\"], \n",
    "                            best_split[\"threshold\"], \n",
    "                            lst, rst, \n",
    "                            best_split[\"info_gain\"]) # as its not a leat node we donot pass 'value' \n",
    "\n",
    "        # if splitting conditions is not met ... we have reached a leaf node\n",
    "        # compute leaf value\n",
    "        leafValue = self.calc_leaf_value(y)\n",
    "        return Node(value = leafValue)\n",
    "\n",
    "\n",
    "    def get_best_split(self, data, no_samples, no_features):\n",
    "        best_split = {}\n",
    "        max_info_gain = -float('inf') # selected minimum value for max info gain : -ve infinity\n",
    "\n",
    "        # iterate over all features\n",
    "        for fi in range(no_features):\n",
    "            feature_value = data[:,fi]\n",
    "            possible_thresholds = np.unique(feature_value)\n",
    "            # threshhold values are real num and \n",
    "            # it is practically impossible to iterate through all the threshhold values\n",
    "            # thus we make a finite list of possible_thresholds\n",
    "            for th in possible_thresholds:\n",
    "\n",
    "                # splitting the data into left_data and right_data\n",
    "                left_data, right_data = self.split(data,fi,th)\n",
    "\n",
    "                # ensuring that any of the and right_data is not empty\n",
    "                if len(left_data) > 0 and len(right_data) > 0:\n",
    "                    y = data[:,-1]\n",
    "                    left_y = left_data[:,-1]\n",
    "                    right_y = right_data[:,-1]\n",
    "\n",
    "                    # computing the info gain based on the mode specified (default gini)\n",
    "                    curr_info_gain = self.compute_info_gain(y, left_y, right_y, self.mode)\n",
    "\n",
    "                    # if we get higher information gain than previous then we select that split\n",
    "                    if curr_info_gain > max_info_gain:\n",
    "                        best_split['feature_index'] = fi\n",
    "                        best_split['threshold'] = th\n",
    "                        best_split['left_data'] = left_data\n",
    "                        best_split['right_data'] = right_data\n",
    "                        best_split['info_gain'] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "\n",
    "        return best_split\n",
    "\n",
    "\n",
    "    def split(self, data, feature_index, threshold):\n",
    "\n",
    "        # split the into left child and right child based on threshhold\n",
    "        left_data = np.array([row for row in data if row[feature_index] <= threshold])\n",
    "        right_data = np.array([row for row in data if row[feature_index] > threshold])\n",
    "        return left_data, right_data\n",
    "\n",
    "    def compute_info_gain(self, parent, left, right, mode='entropy'):\n",
    "        # computing left weight (wl) & right weight (wr)\n",
    "        wl = len(left)/len(parent)\n",
    "        wr = len(right)/len(parent)\n",
    "\n",
    "        if mode == 'entropy':\n",
    "            # ig = information gain\n",
    "            ig = self.entropy(parent) - ( wl*self.entropy(left) + wr*self.entropy(right) )\n",
    "        else:\n",
    "            ig = self.gini_index(parent) - ( wl*self.gini_index(left) + wr*self.gini_index(right) )\n",
    "\n",
    "        return ig\n",
    "\n",
    "    def entropy(self, y):\n",
    "        entropy = 0\n",
    "        labels = np.unique(y) # class labels\n",
    "        for l in labels:\n",
    "            p = len(y[y == l]) / len(y)\n",
    "            entropy += -p * np.log2(p)\n",
    "        return entropy\n",
    "\n",
    "    def gini_index(self,y):\n",
    "        g = 0\n",
    "        labels = np.unique(y) # class labels\n",
    "        for l in labels:\n",
    "            p = len(y[y == l]) / len(y)\n",
    "            g += p**2\n",
    "        gi = 1 - g\n",
    "        return gi\n",
    "\n",
    "    def calc_leaf_value(self,y):\n",
    "        y = list(y)\n",
    "        return max(y, key=y.count)\n",
    "\n",
    "    def print_tree(self,tree=None,indent=\"  \"):\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "        if tree.value is not None: # print value of leaf node\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(f\"X_ {tree.feature_index} <=  {tree.threshold} ? Info gain = {tree.info_gain}\")\n",
    "            print(f\"{indent}left:\",end='')\n",
    "            self.print_tree(tree.left, indent+indent)\n",
    "            print(f\"{indent}right:\",end='')\n",
    "            self.print_tree(tree.right, indent+indent)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        data = np.concatenate((X,y),axis=1)\n",
    "        self.root = self.build_tree(data)\n",
    "\n",
    "    def predict(self,X):\n",
    "        # predict set of values\n",
    "        predictions = [self.make_predictions(x, self.root) for x in X]\n",
    "        return np.array(predictions).reshape(-1,1)\n",
    "\n",
    "    def make_predictions(self,x,tree):\n",
    "        # to predict a single data point\n",
    "\n",
    "        if tree.value != None: # leaf node\n",
    "            return tree.value \n",
    "        feature_val = x[tree.feature_index] # extracting feature value at a giveb feature index\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_predictions(x,tree.left)\n",
    "        else:\n",
    "            return self.make_predictions(x,tree.right)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = iris.iloc[:,:-1].values\n",
    "y = iris.iloc[:,-1].values.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_ 2 <=  1.9 ? Info gain = 0.3298816872427983\n",
      "  left:Iris-setosa\n",
      "  right:X_ 3 <=  1.6 ? Info gain = 0.3832877944691655\n",
      "    left:X_ 2 <=  4.9 ? Info gain = 0.13999999999999996\n",
      "        left:Iris-versicolor\n",
      "        right:X_ 0 <=  6.0 ? Info gain = 0.11999999999999983\n",
      "                left:Iris-virginica\n",
      "                right:Iris-virginica\n",
      "    right:X_ 2 <=  4.8 ? Info gain = 0.011005353955978708\n",
      "        left:X_ 1 <=  3.0 ? Info gain = 0.375\n",
      "                left:Iris-virginica\n",
      "                right:Iris-versicolor\n",
      "        right:Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier_scratch(min_samples_split=2, max_depth=3, mode='gini')\n",
    "model.fit(X_train,y_train)\n",
    "model.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = accuracy_score(y_test, y_pred_test)*100\n",
    "train_acc = accuracy_score(y_train, y_pred_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 99.16666666666667%\n",
      "test accuracy 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "print(f\"train accuracy {train_acc}%\")\n",
    "print(f\"test accuracy {test_acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Random forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-884d89bd1594>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf = rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 100.0%\n",
      "test accuracy 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_pred_test)*100\n",
    "train_acc = accuracy_score(y_train, y_pred_train)*100\n",
    "\n",
    "print(f\"train accuracy {train_acc}%\")\n",
    "print(f\"test accuracy {test_acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model = DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=1)\n",
    "iris_model.fit(X_train,y_train)\n",
    "\n",
    "train_pred = iris_model.predict(X_train)\n",
    "test_pred = iris_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train accuracy\n",
    "accuracy_score(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "# depth from 2 to 20\n",
    "depths = range(1,21)\n",
    "for depth in depths:\n",
    "    # make model (of required depth) and fit that model\n",
    "    model = DecisionTreeClassifier(max_depth=depth)\n",
    "    model = model.fit(X_train, y_train)\n",
    "\n",
    "    # predict train and test labels\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # calc accuracy of train and test and keep appending in seperate lists\n",
    "    train_acc_list.append( accuracy_score(y_train, y_pred_train) )\n",
    "    test_acc_list.append( accuracy_score(y_test, y_pred_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6916666666666667, 0.9583333333333334, 0.9833333333333333, 0.9916666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.5666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667]\n"
     ]
    }
   ],
   "source": [
    "print(train_acc_list)\n",
    "print(test_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "depth_list = range(1,21)\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "plt.plot(depth_list, train_acc_list, label='Train Accuracy', color='black')\n",
    "plt.plot(depth_list, test_acc_list, label='Test Accuracy', color='blue')\n",
    "\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetalLengthCm    0.476940\n",
       "PetalWidthCm     0.366544\n",
       "SepalLengthCm    0.124420\n",
       "SepalWidthCm     0.032097\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.Series(rf.feature_importances_, index = iris.columns[:-1])\n",
    "feature_imp.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Random forest from scratch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_forest(train, test, max_depth, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sonar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 207 entries, 0 to 206\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0.0200  207 non-null    float64\n",
      " 1   0.0371  207 non-null    float64\n",
      " 2   0.0428  207 non-null    float64\n",
      " 3   0.0207  207 non-null    float64\n",
      " 4   0.0954  207 non-null    float64\n",
      " 5   0.0986  207 non-null    float64\n",
      " 6   0.1539  207 non-null    float64\n",
      " 7   0.1601  207 non-null    float64\n",
      " 8   0.3109  207 non-null    float64\n",
      " 9   0.2111  207 non-null    float64\n",
      " 10  0.1609  207 non-null    float64\n",
      " 11  0.1582  207 non-null    float64\n",
      " 12  0.2238  207 non-null    float64\n",
      " 13  0.0645  207 non-null    float64\n",
      " 14  0.0660  207 non-null    float64\n",
      " 15  0.2273  207 non-null    float64\n",
      " 16  0.3100  207 non-null    float64\n",
      " 17  0.2999  207 non-null    float64\n",
      " 18  0.5078  207 non-null    float64\n",
      " 19  0.4797  207 non-null    float64\n",
      " 20  0.5783  207 non-null    float64\n",
      " 21  0.5071  207 non-null    float64\n",
      " 22  0.4328  207 non-null    float64\n",
      " 23  0.5550  207 non-null    float64\n",
      " 24  0.6711  207 non-null    float64\n",
      " 25  0.6415  207 non-null    float64\n",
      " 26  0.7104  207 non-null    float64\n",
      " 27  0.8080  207 non-null    float64\n",
      " 28  0.6791  207 non-null    float64\n",
      " 29  0.3857  207 non-null    float64\n",
      " 30  0.1307  207 non-null    float64\n",
      " 31  0.2604  207 non-null    float64\n",
      " 32  0.5121  207 non-null    float64\n",
      " 33  0.7547  207 non-null    float64\n",
      " 34  0.8537  207 non-null    float64\n",
      " 35  0.8507  207 non-null    float64\n",
      " 36  0.6692  207 non-null    float64\n",
      " 37  0.6097  207 non-null    float64\n",
      " 38  0.4943  207 non-null    float64\n",
      " 39  0.2744  207 non-null    float64\n",
      " 40  0.0510  207 non-null    float64\n",
      " 41  0.2834  207 non-null    float64\n",
      " 42  0.2825  207 non-null    float64\n",
      " 43  0.4256  207 non-null    float64\n",
      " 44  0.2641  207 non-null    float64\n",
      " 45  0.1386  207 non-null    float64\n",
      " 46  0.1051  207 non-null    float64\n",
      " 47  0.1343  207 non-null    float64\n",
      " 48  0.0383  207 non-null    float64\n",
      " 49  0.0324  207 non-null    float64\n",
      " 50  0.0232  207 non-null    float64\n",
      " 51  0.0027  207 non-null    float64\n",
      " 52  0.0065  207 non-null    float64\n",
      " 53  0.0159  207 non-null    float64\n",
      " 54  0.0072  207 non-null    float64\n",
      " 55  0.0167  207 non-null    float64\n",
      " 56  0.0180  207 non-null    float64\n",
      " 57  0.0084  207 non-null    float64\n",
      " 58  0.0090  207 non-null    float64\n",
      " 59  0.0032  207 non-null    float64\n",
      " 60  R       207 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 98.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sr = pd.read_csv(\"sonar.csv\")\n",
    "sr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60f5decb5d5f75cee078769f31acc91db8399f71b0160f2efe6eadfe23786558"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
